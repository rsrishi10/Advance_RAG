{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello. how are you? I am fine!  \"\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello. ', 'how are you? ', 'I am fine!']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello.  how are you?  I am fine!\n"
     ]
    }
   ],
   "source": [
    "print(nodes[1].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello. foo bar. cat dog. mouse\"\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello. ', 'foo bar. ', 'cat dog. ', 'mouse']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello.  foo bar.  cat dog.  mouse\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# Configure the embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Set the global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = node_parser\n",
    "# Create the index\n",
    "sentence_index = VectorStoreIndex.from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from copy import deepcopy\n",
    "\n",
    "scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\n",
    "nodes_old = [deepcopy(n) for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo bar. '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_old[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_nodes = postproc.postprocess_nodes(scored_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello.  foo bar.  cat dog.  mouse\n"
     ]
    }
   ],
   "source": [
    "print(replaced_nodes[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "# BAAI/bge-reranker-base\n",
    "# link: https://huggingface.co/BAAI/bge-reranker-base\n",
    "rerank = SentenceTransformerRerank(\n",
    "    top_n=2, model=\"BAAI/bge-reranker-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import TextNode, NodeWithScore\n",
    "\n",
    "query = QueryBundle(\"I want a dog.\")\n",
    "\n",
    "scored_nodes = [\n",
    "    NodeWithScore(node=TextNode(text=\"This is a cat\"), score=0.6),\n",
    "    NodeWithScore(node=TextNode(text=\"This is a dog\"), score=0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_nodes = rerank.postprocess_nodes(\n",
    "    scored_nodes, query_bundle=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This is a dog', 0.91827416), ('This is a cat', 0.0014040753)]\n"
     ]
    }
   ],
   "source": [
    "print([(x.text, x.score) for x in reranked_nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing the query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community. Additionally, collaborating with others, influencing, and being influenced by others are critical aspects for success in AI career development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    Settings.llm = llm\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.node_parser = node_parser\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(documents)\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "        sentence_index = load_index_from_storage(storage_context)\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "index = build_sentence_window_index(\n",
    "    [document],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruLens Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('generated_questions.text', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from local_utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence window size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.callbacks.base.CallbackManager'> because of class\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic.fields.FieldInfo'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic._internal._repr.Representation'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> because of class\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> because of class\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.data_structs.data_structs.IndexDict'> because of class\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.storage_context.StorageContext'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x151e89240> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x417ddf400>, 'In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x156be0b80> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x417ddf400>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x152ae41f0> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x417d6bcd0>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x156101c60> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x417d6bcd0>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function MetadataReplacementPostProcessor._postprocess_nodes at 0x152e59ea0> with (MetadataReplacementPostProcessor(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, target_metadata_key='window'), [NodeWithScore(node=TextNode(id_='62da1762-6d15-46bc-a605-6e32b653c37f', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='92e9f902-501f-49a8-b34b-daa0065caaed', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5', mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='7d459aee-364d-4984-9e5c-d192e4f56696', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae5d9141-cf34-4359-84b7-bf34d83a4056', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='938798b2-d69b-490a-ac83-c0004a420ef0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='0832302f-6df2-4b0a-a55b-ca15f3b6859f', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3602c9f5-b15d-41b9-b730-7f5a5ef8a604', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='938798b2-d69b-490a-ac83-c0004a420ef0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d459aee-364d-4984-9e5c-d192e4f56696', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fb557e11-16d9-4ab0-8df2-86c6d70a49f9', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='8abed637-0750-4855-baef-ead3e9ee7b58', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23b070a5-05eb-453f-8b7e-205d910d5b1c', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='4b040e99-79db-43f8-9191-12167ef5b1e5', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c6a5c90-2061-4178-86ce-dc5e9e174a3e', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34be2763-65c9-4418-8477-ef93e8745669', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. ', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function SentenceTransformerRerank._postprocess_nodes at 0x152ed8b80> with (SentenceTransformerRerank(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, model='BAAI/bge-reranker-base', top_n=2, device='mps', keep_retrieval_score=False, trust_remote_code=False), [NodeWithScore(node=TextNode(id_='62da1762-6d15-46bc-a605-6e32b653c37f', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='92e9f902-501f-49a8-b34b-daa0065caaed', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='7d459aee-364d-4984-9e5c-d192e4f56696', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae5d9141-cf34-4359-84b7-bf34d83a4056', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='938798b2-d69b-490a-ac83-c0004a420ef0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='0832302f-6df2-4b0a-a55b-ca15f3b6859f', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3602c9f5-b15d-41b9-b730-7f5a5ef8a604', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='938798b2-d69b-490a-ac83-c0004a420ef0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d459aee-364d-4984-9e5c-d192e4f56696', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fb557e11-16d9-4ab0-8df2-86c6d70a49f9', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='8abed637-0750-4855-baef-ead3e9ee7b58', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23b070a5-05eb-453f-8b7e-205d910d5b1c', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='4b040e99-79db-43f8-9191-12167ef5b1e5', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c6a5c90-2061-4178-86ce-dc5e9e174a3e', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34be2763-65c9-4418-8477-ef93e8745669', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function CompactAndRefine.get_response at 0x152e2dfc0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x417ddf7c0>,)\n",
      "calling <function Refine.get_response at 0x152e2d5a0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x417ddf7c0>,)\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f0ab0a5fc04d6ea0c3f1731d3ad06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.134:64368 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tru().run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence window size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.callbacks.base.CallbackManager'> because of class\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> because of class\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> because of class\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.data_structs.data_structs.IndexDict'> because of class\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.storage_context.StorageContext'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x151e89240> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x440c4b9a0>, 'In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x156be0b80> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x440c4b9a0>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x152ae41f0> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x43c8fe530>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x156101c60> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x43c8fe530>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function MetadataReplacementPostProcessor._postprocess_nodes at 0x152e59ea0> with (MetadataReplacementPostProcessor(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, target_metadata_key='window'), [NodeWithScore(node=TextNode(id_='62da1762-6d15-46bc-a605-6e32b653c37f', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='92e9f902-501f-49a8-b34b-daa0065caaed', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5', mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='7d459aee-364d-4984-9e5c-d192e4f56696', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae5d9141-cf34-4359-84b7-bf34d83a4056', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='938798b2-d69b-490a-ac83-c0004a420ef0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='0832302f-6df2-4b0a-a55b-ca15f3b6859f', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3602c9f5-b15d-41b9-b730-7f5a5ef8a604', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='938798b2-d69b-490a-ac83-c0004a420ef0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d459aee-364d-4984-9e5c-d192e4f56696', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fb557e11-16d9-4ab0-8df2-86c6d70a49f9', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='8abed637-0750-4855-baef-ead3e9ee7b58', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23b070a5-05eb-453f-8b7e-205d910d5b1c', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='4b040e99-79db-43f8-9191-12167ef5b1e5', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c6a5c90-2061-4178-86ce-dc5e9e174a3e', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34be2763-65c9-4418-8477-ef93e8745669', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. ', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function SentenceTransformerRerank._postprocess_nodes at 0x152ed8b80> with (SentenceTransformerRerank(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, model='BAAI/bge-reranker-base', top_n=2, device='mps', keep_retrieval_score=False, trust_remote_code=False), [NodeWithScore(node=TextNode(id_='62da1762-6d15-46bc-a605-6e32b653c37f', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='92e9f902-501f-49a8-b34b-daa0065caaed', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='7d459aee-364d-4984-9e5c-d192e4f56696', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae5d9141-cf34-4359-84b7-bf34d83a4056', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='938798b2-d69b-490a-ac83-c0004a420ef0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='0832302f-6df2-4b0a-a55b-ca15f3b6859f', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3602c9f5-b15d-41b9-b730-7f5a5ef8a604', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='938798b2-d69b-490a-ac83-c0004a420ef0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d459aee-364d-4984-9e5c-d192e4f56696', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fb557e11-16d9-4ab0-8df2-86c6d70a49f9', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='8abed637-0750-4855-baef-ead3e9ee7b58', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='966933c2-6143-4b43-93a7-40fea7202216', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23b070a5-05eb-453f-8b7e-205d910d5b1c', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='4b040e99-79db-43f8-9191-12167ef5b1e5', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c6a5c90-2061-4178-86ce-dc5e9e174a3e', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34be2763-65c9-4418-8477-ef93e8745669', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function CompactAndRefine.get_response at 0x152e2dfc0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x41673b580>,)\n",
      "calling <function Refine.get_response at 0x152e2d5a0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x41673b580>,)\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.134:64368\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tru().run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('generated_questions.text', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence window size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.callbacks.base.CallbackManager'> because of class\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> because of class\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> because of class\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.data_structs.data_structs.IndexDict'> because of class\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.storage_context.StorageContext'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "sentence_index_3 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x151e89240> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x416724700>, 'In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x156be0b80> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x416724700>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x152ae41f0> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x4167242e0>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x156101c60> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x4167242e0>, QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function MetadataReplacementPostProcessor._postprocess_nodes at 0x152e59ea0> with (MetadataReplacementPostProcessor(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, target_metadata_key='window'), [NodeWithScore(node=TextNode(id_='cdc8b6f3-53cc-43e9-b077-bf5ab91f4136', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='22e18b37-6fc6-497a-87f3-8760ec844e85', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5', mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='f27203b0-6330-429d-87da-6029743ce3e2', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4f400eb-c7c1-4876-b7f9-dbf2f16f61f1', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e5c371a-7f8d-4938-97d3-535df36590a0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='82f438bc-640d-403d-a364-fcfd18a30ede', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af243186-043f-46b9-8272-da87be7f0721', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='752e43e1-7b32-4ff5-9db1-2a440c541cad', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='3e5c371a-7f8d-4938-97d3-535df36590a0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f27203b0-6330-429d-87da-6029743ce3e2', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='076302d6-56e6-4e55-bb8d-270af886b695', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='489af2f8-b067-4aa7-9e10-61464c4d769b', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='752e43e1-7b32-4ff5-9db1-2a440c541cad', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2982b6f2-7848-458b-878c-00385581dbbd', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='2a098e8a-2d48-47d9-b0c9-d36e0c1df3bc', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3dccaae3-6759-4dce-9c7e-9663ddcf5259', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='539a02f6-daeb-4909-ad84-ac102fbb03cf', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. ', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function SentenceTransformerRerank._postprocess_nodes at 0x152ed8b80> with (SentenceTransformerRerank(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x157ae24a0>, model='BAAI/bge-reranker-base', top_n=2, device='mps', keep_retrieval_score=False, trust_remote_code=False), [NodeWithScore(node=TextNode(id_='cdc8b6f3-53cc-43e9-b077-bf5ab91f4136', embedding=None, metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': 'Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cb425a41-65c1-4cbe-b628-70091c2537bc', node_type='4', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='74f89a18cf6abf307fe2c0c7b3b287f205ca091b3d19726aceb51c2107945393'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='22e18b37-6fc6-497a-87f3-8760ec844e85', node_type='1', metadata={'page_label': '19', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': \"✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\n Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", 'original_text': \"You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. \"}, hash='360c628693c3b40af23926bbf7f50fe98d1d0e08e919cf8c860e05888c9c07c5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Here’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis.  It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete.  You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile.  Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\", mimetype='text/plain', start_char_idx=1889, end_char_idx=2113, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7542267266169244), NodeWithScore(node=TextNode(id_='f27203b0-6330-429d-87da-6029743ce3e2', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4f400eb-c7c1-4876-b7f9-dbf2f16f61f1', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess. ', 'original_text': 'When taking a shot is inexpensive, it also makes sense to take many shots. '}, hash='e6ce7ed57824373992dbac124cde1c3d15d06146d7e0c519d90643d99e8d2c98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e5c371a-7f8d-4938-97d3-535df36590a0', node_type='1', metadata={'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, hash='650595849984595fb823b7b69ee7ddc55a597b51bed700ede1665c5095837410')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', mimetype='text/plain', start_char_idx=1412, end_char_idx=1498, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7460037059434735), NodeWithScore(node=TextNode(id_='82f438bc-640d-403d-a364-fcfd18a30ede', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', 'original_text': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af243186-043f-46b9-8272-da87be7f0721', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo.  Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. ', 'original_text': 'Both approaches have their advocates, and the best choice depends on the situation.\\n'}, hash='18e3ea0da999d49c1ba86d9b6414ee1c176aa7c7b54c9ea205a99e63ef4cfa4b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='752e43e1-7b32-4ff5-9db1-2a440c541cad', node_type='1', metadata={'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='8ec1bb21f93a75b1ad3cd6593767f6158ea6bd2ac771c85503be102b00d91230')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources?  Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. ', mimetype='text/plain', start_char_idx=562, end_char_idx=709, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7456274123880507), NodeWithScore(node=TextNode(id_='3e5c371a-7f8d-4938-97d3-535df36590a0', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', 'original_text': 'After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f27203b0-6330-429d-87da-6029743ce3e2', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive. ', 'original_text': 'In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n'}, hash='f176c17b2eea5c92cf98d1b418f018c87f1aefd963e247b012e3d0a57c5c98f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='076302d6-56e6-4e55-bb8d-270af886b695', node_type='1', metadata={'window': 'When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n', 'original_text': 'Building models is an iterative \\nprocess. '}, hash='55716e2adbb2aa8b84422cbca0b155417e4b099b56c9506c10780ffaa393c8b1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim.  Building models is an iterative \\nprocess.  For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. ', mimetype='text/plain', start_char_idx=1498, end_char_idx=1658, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7267226369110432), NodeWithScore(node=TextNode(id_='489af2f8-b067-4aa7-9e10-61464c4d769b', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', 'original_text': 'Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='752e43e1-7b32-4ff5-9db1-2a440c541cad', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\n Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots. ', 'original_text': 'For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n'}, hash='cf660fc435e666bc18c7c52da783f928c77d06db991ef665d3bfe8402ba188b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2982b6f2-7848-458b-878c-00385581dbbd', node_type='1', metadata={'window': 'Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n After agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. ', 'original_text': 'For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. '}, hash='e8d58e6c56294d13e9115fb57a59539bc7b6c91c596172118e18be07825bd70f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Both approaches have their advocates, and the best choice depends on the situation.\\n Ready, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be.  For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\n Ready, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work.  For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly.  When taking a shot is inexpensive, it also makes sense to take many shots.  In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\n', mimetype='text/plain', start_char_idx=944, end_char_idx=1118, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.71008256232576), NodeWithScore(node=TextNode(id_='2a098e8a-2d48-47d9-b0c9-d36e0c1df3bc', embedding=None, metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', 'original_text': 'Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. '}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='87022b7f-bedb-4a76-941f-84914a254432', node_type='4', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09'}, hash='84406ac1dbc40d76e542cb71f5ab08573ddcc32ba81c7343f83ec4b479617854'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3dccaae3-6759-4dce-9c7e-9663ddcf5259', node_type='1', metadata={'page_label': '20', 'file_name': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_path': 'eBook-How-to-Build-a-Career-in-AI.pdf', 'file_type': 'application/pdf', 'file_size': 3717673, 'creation_date': '2025-01-11', 'last_modified_date': '2025-01-09', 'window': 'For many applications, the cost of training and conducting error analysis is not \\nprohibitive.  Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing. ', 'original_text': 'But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n'}, hash='e264b0a5b52e463ce9dcb064e570da75cff24073ca6e3e3b81b4ace71ef77fd6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='539a02f6-daeb-4909-ad84-ac102fbb03cf', node_type='1', metadata={'window': 'So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n ✓\\n✓', 'original_text': 'Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n'}, hash='be4044aa8c911bc5e91880782df36fbf1e981b8ae12f8209b2aa616bffed2c8a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters.  So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\n But when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\n Ready, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation.  Commit and \\nexecute only when you have a high degree of confidence in a direction.\\n Ready, Fire, Aim: Jump into development and start executing.  This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n', mimetype='text/plain', start_char_idx=2245, end_char_idx=2329, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6616211919501738)], QueryBundle(query_str='In the context of project selection and execution, explain the difference between the \"Ready, Aim, Fire\" and \"Ready, Fire, Aim\" approaches. Provide examples where each approach might be more beneficial.', image_path=None, custom_embedding_strs=None, embedding=[-0.012468641623854637, 0.046670157462358475, 0.009735949337482452, -0.03896990418434143, 0.044657833874225616, 0.0077745188027620316, 0.03731531649827957, -0.0329585075378418, -0.01386626623570919, -0.03695371374487877, 0.0042763021774590015, -0.023708468303084373, -0.05516844615340233, 0.020636845380067825, 0.016353555023670197, 0.06976449489593506, -0.04971760883927345, -0.06460925936698914, 0.004527615383267403, 0.010709005407989025, 0.03448287770152092, -0.03362516313791275, 0.06106363236904144, -0.01384020410478115, 0.06935474276542664, 0.03837447613477707, 0.008383717387914658, -0.03867623209953308, 0.013609894551336765, -0.13529647886753082, -0.002849593758583069, 0.03090880624949932, 0.02146477811038494, -0.06186351925134659, -0.03243793174624443, 0.024771656841039658, 0.0025367767084389925, 0.04220819100737572, -0.05620260909199715, 0.002851022407412529, 0.031850170344114304, 0.06156656891107559, 0.015219041146337986, -0.05463950335979462, -0.061133623123168945, -0.002857490675523877, 0.046982068568468094, -0.05486111342906952, -0.06253112107515335, -0.01783367432653904, -0.03766080364584923, -0.0652131736278534, -0.06152445450425148, -0.009203631430864334, -0.0035383207723498344, 0.0015562495682388544, -0.028695372864603996, 0.07789161056280136, -0.02635473757982254, 0.04156811162829399, 0.025874657556414604, 0.003112796461209655, -0.16919760406017303, 0.10243102163076401, 0.06296432018280029, -0.005634586792439222, 0.006511477753520012, -0.017551753669977188, -0.017034973949193954, 0.10240084677934647, -0.017396530136466026, 0.033131904900074005, -0.01389173325151205, 0.037682078778743744, 0.01451553963124752, -0.031713612377643585, -0.0273139551281929, 0.01759640872478485, 0.06810205429792404, -0.04842180758714676, 0.04810011386871338, 0.04566563665866852, -0.030051585286855698, 0.01602131687104702, -0.020756252110004425, -0.002368557034060359, 0.010675471276044846, 0.0478488989174366, 0.09764816612005234, -0.010885168798267841, -0.003678243840113282, -0.03300028666853905, 0.0003613729204516858, 0.006377281155437231, -0.014471892267465591, -0.05836856737732887, 0.04217271879315376, 0.009762103669345379, -0.06013607978820801, 0.3299696147441864, -0.041665978729724884, -0.005520110484212637, 0.008014137856662273, 0.020160753279924393, 0.013096097856760025, -0.015698714181780815, -0.0021197148598730564, -0.024483846500515938, -0.00906221941113472, 0.0004922464722767472, 0.03506341576576233, -0.017591457813978195, 0.003230116330087185, -0.056273143738508224, -0.01895883120596409, -0.010447187349200249, 0.03686157241463661, -0.04211884364485741, 0.021959252655506134, -0.047342583537101746, 0.054844118654727936, -0.023059329017996788, 0.04412110522389412, -0.06555847823619843, -0.07317864149808884, -0.011995812878012657, 0.030720075592398643, 0.06959687173366547, -0.0034866919741034508, -0.036948010325431824, 0.05422830581665039, -0.011104553006589413, -0.07469552010297775, -0.028217583894729614, -0.015544838272035122, 0.05651082843542099, 0.0035314559936523438, 0.010648299939930439, -0.02964114211499691, 0.01899268850684166, 0.04663911461830139, 0.030394136905670166, 0.0647035613656044, -0.05120926350355148, -0.05144675821065903, 0.13821454346179962, -0.014492671005427837, 0.011351889930665493, -0.05271109938621521, 0.020173151046037674, -0.02156881056725979, 0.02603781409561634, 0.008206811733543873, -0.018304113298654556, -0.04062129557132721, 0.017643878236413002, -0.07657033950090408, -0.006150687113404274, 0.006023138761520386, -0.032291263341903687, -0.012877454981207848, 0.0031991919968277216, -0.04235498234629631, 0.0296605434268713, -0.023728733882308006, -0.07849056273698807, -0.017177047207951546, -0.0068365903571248055, -0.041152339428663254, -0.022827303037047386, -0.07970849424600601, -0.0010714707896113396, 0.009663073346018791, -0.04864883795380592, 0.031981583684682846, 0.0030847941525280476, -0.02727244794368744, -0.00849563255906105, 0.04737873002886772, 0.030850637704133987, 0.09090965241193771, -0.038623109459877014, 0.04593474790453911, 0.019261019304394722, 0.023019475862383842, -0.07064876705408096, -0.07953284680843353, 0.009268492460250854, 0.056078072637319565, 0.061346590518951416, -0.07060030102729797, 0.007697168737649918, 0.03995911404490471, 0.06210910901427269, -0.055296868085861206, 0.05692853778600693, 0.025826822966337204, -0.03029177337884903, -0.007859962992370129, -0.02718197926878929, 0.004005974158644676, 0.0878455713391304, -0.031519655138254166, -0.014889530837535858, -0.017070278525352478, 0.01705588586628437, 0.028558949008584023, -0.07806950062513351, 0.08668569475412369, -0.0011163171147927642, -0.12319254875183105, 0.04903459548950195, -0.008180362172424793, 0.018930017948150635, -0.02508298121392727, -0.023967621847987175, 0.02640947885811329, 0.05385651811957359, -0.08479159325361252, 0.07164591550827026, -0.011303246952593327, -0.011918491683900356, 0.08052235841751099, -0.2763381600379944, -0.027659066021442413, 0.0009787216549739242, -0.019999314099550247, 0.053243014961481094, -0.0072945598512887955, 0.002244721632450819, -0.04316198080778122, -0.06073172762989998, 0.028451822698116302, 0.07028015702962875, -0.0511920228600502, -0.0028423857875168324, 0.0010980976512655616, 0.0050619239918887615, -0.03100288100540638, -0.03271624445915222, -0.08230486512184143, -0.0239549670368433, 0.023332629352808, 0.011153453029692173, -0.016810627654194832, -0.018010614439845085, -0.04734205827116966, -0.00016682114801369607, 0.02419975958764553, 0.07995489984750748, -0.008189201354980469, 0.07526135444641113, -0.00602300139144063, 0.03815542161464691, 0.038673385977745056, -0.041591349989175797, -0.05327706038951874, 0.03095007874071598, -0.023439878597855568, 0.08687011897563934, 0.03125354275107384, -0.016097011044621468, -0.004262830596417189, 0.011455136351287365, 0.04737522825598717, 0.00016662973212078214, -0.0075897895731031895, -0.03021593764424324, 0.012461531907320023, -0.07693912088871002, -0.010791069827973843, -0.012145627290010452, 0.058482956141233444, 0.021230056881904602, 0.06707996129989624, -0.003944424446672201, -0.027962248772382736, -0.04467153549194336, 2.1071853097964777e-06, -0.12545344233512878, 0.03628169000148773, -0.01015265379101038, -0.005747965071350336, 0.036609455943107605, -0.016752639785408974, -0.0365881621837616, 0.026924729347229004, 0.04389101266860962, -0.019040921702980995, 0.009503934532403946, -0.043889231979846954, 0.003476586891338229, -0.006926096510142088, -0.022729920223355293, 0.08082141727209091, -0.03803294152021408, -0.051832545548677444, 0.01851806603372097, -0.01277443952858448, -0.02793503738939762, 0.002560508670285344, 0.02824924699962139, 0.03094291500747204, 0.026471830904483795, 0.013482315465807915, 0.03387441858649254, 0.018750231713056564, -0.014306728728115559, -0.029012922197580338, 0.06063335761427879, -0.026330316439270973, -0.007576393894851208, -0.007651467341929674, -0.030845748260617256, -0.0040736268274486065, 0.011186153627932072, -0.03365079313516617, 0.01645500399172306, -0.06623979657888412, -0.2704678773880005, 0.04341014847159386, 0.06528790295124054, 0.016363130882382393, -0.0107783954590559, -0.03826463222503662, 9.704699914436787e-05, -0.09461428225040436, -0.003969991579651833, 0.08243465423583984, 0.002023620530962944, -0.021271347999572754, -0.0015177484601736069, 0.03266996890306473, -0.04602765291929245, 0.037490151822566986, 0.12195325642824173, -0.03616682440042496, 0.03027961589396, -0.022155458107590675, 0.003845736151561141, -0.012961427681148052, 0.156653493642807, 0.003363794181495905, 0.05148701369762421, -0.027159137651324272, 0.020275983959436417, 0.022614702582359314, 0.019079839810729027, 0.04525933787226677, 0.06361179798841476, -0.02720358408987522, 0.07194843888282776, -0.01905871368944645, 0.013102062977850437, -0.0022177542559802532, 0.028777288272976875, 0.11578915268182755, 0.050593115389347076, 0.01669633388519287, -0.04320831596851349, 0.01850196160376072, 0.024498505517840385, 0.000617568613961339, 0.07143428921699524, -0.027047205716371536, -0.042252495884895325, -0.07354532182216644, -0.06937308609485626, -0.025304432958364487, -0.024401551112532616, -0.014874501153826714, -0.03952017426490784, 0.009508151561021805, 0.02019377239048481, 0.06418965756893158, -0.01969355344772339, -0.018419448286294937, -0.06216113269329071, 0.08988485485315323, 0.05571049079298973, 0.06070716679096222, 0.08150981366634369, 0.017709003761410713, -0.002613372402265668]))\n",
      "calling <function CompactAndRefine.get_response at 0x152e2dfc0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x416724340>,)\n",
      "calling <function Refine.get_response at 0x152e2d5a0> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x416724340>,)\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.134:64368\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tru().run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
